#!/usr/bin/env python3
"""
RAG ULTRA v0.1 - –°–∫—Ä–∏–ø—Ç –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
–ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (Windows/Linux/MacOS)
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python quickstart.py
"""

import os
import sys
import subprocess
from pathlib import Path
import shutil


def run_command(cmd, shell=True, check=True):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ"""
    try:
        result = subprocess.run(
            cmd, shell=shell, check=check, capture_output=True, text=True)
        return result.returncode == 0, result.stdout
    except subprocess.CalledProcessError as e:
        return False, str(e)


def check_conda():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è conda"""
    return shutil.which('conda') is not None


def check_environment():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è corp-rag"""
    success, output = run_command("conda env list")
    return success and "corp-rag" in output


def create_directories():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    dirs = [
        "doc_ingest/models",
        "doc_ingest/doc/PDF",
        "doc_ingest/doc/WORD",
        "doc_ingest/doc/EXCEL",
        "doc_ingest/doc/PPTX",
        "doc_ingest/doc/TXT_MD",
        "doc_ingest/outputs/dataset",
        "doc_ingest/outputs/index",
        "doc_ingest/outputs/media",
        "doc_ingest/outputs/graphs"
    ]

    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)

    return True


def check_models():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π"""
    embed_model = Path(
        "doc_ingest/models/sbert_large_nlu_ru/model.safetensors")
    rerank_model = Path("doc_ingest/models/reranker_ru/model.safetensors")

    return embed_model.exists(), rerank_model.exists()


def download_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    embed_exists, rerank_exists = check_models()

    if not embed_exists:
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)...")
        code = """
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='ai-forever/sbert_large_nlu_ru',
    repo_type='model',
    local_dir='doc_ingest/models/sbert_large_nlu_ru',
    local_dir_use_symlinks=False
)
print('‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞')
"""
        try:
            exec(code)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return False
    else:
        print("‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∞–π–¥–µ–Ω–∞")

    if not rerank_exists:
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è...")
        code = """
from sentence_transformers import CrossEncoder
ce = CrossEncoder('DiTy/cross-encoder-russian-msmarco')
ce.save_pretrained('doc_ingest/models/reranker_ru')
print('‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞')
"""
        try:
            exec(code)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return False
    else:
        print("‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–π–¥–µ–Ω–∞")

    return True


def count_documents():
    """–ü–æ–¥—Å—á–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    extensions = ['.pdf', '.docx', '.doc', '.xlsx',
                  '.xls', '.pptx', '.txt', '.md', '.html']
    doc_dir = Path("doc_ingest/doc")

    if not doc_dir.exists():
        return 0

    count = 0
    for ext in extensions:
        count += len(list(doc_dir.rglob(f"*{ext}")))

    return count


def process_documents():
    """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    scripts = [
        ("1Ô∏è‚É£  –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...", "1.main_parse_doc.py"),
        ("2Ô∏è‚É£  –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–ª–µ–π...", "2.main_build_doc_fields_index.py"),
        ("3Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ –ª–µ–∫—Å–∏–∫–æ–Ω–∞...", "3.main_build_field_lexicon.py"),
        ("4Ô∏è‚É£  –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è...", "4.main_embed.py")
    ]

    os.chdir("doc_ingest")

    for message, script in scripts:
        print(message)
        success, _ = run_command(f"python {script}")
        if not success:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ {script}")
            os.chdir("..")
            return False

    os.chdir("..")
    return True


def main():
    print("üöÄ RAG ULTRA v0.1 - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞")
    print("==========================================")
    print()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ conda
    if not check_conda():
        print("‚ùå Conda –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Anaconda –∏–ª–∏ Miniconda")
        print("   –°–∫–∞—á–∞—Ç—å: https://docs.conda.io/en/latest/miniconda.html")
        sys.exit(1)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if check_environment():
        print("‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ corp-rag —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    else:
        print("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ conda –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
        success, _ = run_command("conda env create -f environment.yml")
        if not success:
            print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            sys.exit(1)
        print("‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ")

    print("\n‚ö†Ô∏è  –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥–æ–π:")
    print("   conda activate corp-rag")
    print("   –ó–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞\n")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    try:
        import torch
        import faiss
        import numpy
        print("‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã")
    except ImportError as e:
        print(f"‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {e}")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–∫—Ä—É–∂–µ–Ω–∏–µ corp-rag –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ")
        response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ")
        if response.lower() != 'y':
            sys.exit(0)

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    print("\nüìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞...")
    if create_directories():
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω–∞")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    print("\nü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π...")
    if not download_models():
        print("‚ö†Ô∏è  –ù–µ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("\nüìÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    doc_count = count_documents()

    if doc_count == 0:
        print("‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ doc_ingest/doc/")
        print("   –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏:")
        print("   - PDF —Ñ–∞–π–ª—ã –≤ doc_ingest/doc/PDF/")
        print("   - Word —Ñ–∞–π–ª—ã –≤ doc_ingest/doc/WORD/")
        print("   - Excel —Ñ–∞–π–ª—ã –≤ doc_ingest/doc/EXCEL/")
        print("   - PowerPoint —Ñ–∞–π–ª—ã –≤ doc_ingest/doc/PPTX/")
        print("   - –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ doc_ingest/doc/TXT_MD/")
        response = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤? (y/n): ")
        if response.lower() != 'y':
            sys.exit(0)
    else:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    if Path("doc_ingest/outputs/dataset/elements.jsonl").exists():
        print("\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        response = input("–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å? (y/n): ")
        if response.lower() == 'y' and doc_count > 0:
            print("\nüîÑ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            print("================================")
            if process_documents():
                print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            else:
                print("‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
    elif doc_count > 0:
        print("\nüîÑ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        print("================================")
        if process_documents():
            print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        else:
            print("‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print("\n‚ú® –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("=======================")
    print("\nüìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("\n1. –î–ª—è –∑–∞–ø—É—Å–∫–∞ API —Å–µ—Ä–≤–µ—Ä–∞:")
    print("   conda activate corp-rag")
    print("   cd doc_ingest/service")
    print("   uvicorn search_api:app --reload --host 0.0.0.0 --port 8000")
    print("\n2. API –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É:")
    print("   http://localhost:8000")
    print("   –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    print("\n3. –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã:")
    print("   cd doc_ingest")
    print("   python test_rag_system.py")
    print("\nüìö –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: README.md")


if __name__ == "__main__":
    main()
